# tascj/src/train.py

import argparse
import os
import random
import shutil
import sys
import time
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F
from tqdm import tqdm

# === è·¯å¾„è®¾ç½®ï¼šç¡®ä¿èƒ½å¯¼å…¥ src ä¸‹çš„æ¨¡å— ===
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½• (tascj/src) çš„ä¸Šä¸Šçº§ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT / "tascj" / "src"))

# === ç¯å¢ƒå˜é‡è®¾ç½® (å‚è€ƒåŸä»£ç ) ===
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# torch.multiprocessing.set_sharing_strategy("file_system")
# torch.backends.cudnn.deterministic = True

# === å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ===
import swanlab  # noqa: E402
from config import ExperimentConfig  # noqa: E402
from dataloader import DataLoaderManager  # noqa: E402
from model import ModelManager  # noqa: E402
from modules.logging import get_logger  # noqa: E402
from modules.utils import to_gpu  # noqa: E402
from optimizer import OptimizerManager  # noqa: E402

# ==============================================================================
# è¾…åŠ©å‡½æ•°
# ==============================================================================


def parse_args():
    parser = argparse.ArgumentParser(description="Train MAP Task with SwanLab")
    parser.add_argument(
        "--config", type=str, required=True, help="Path to YAML config file"
    )
    parser.add_argument(
        "--output-root",
        type=str,
        default="artifacts",
        help="Root directory for outputs",
    )
    parser.add_argument(
        "--load-from", type=str, default=None, help="Path to checkpoint to load"
    )
    parser.add_argument("--eval-only", action="store_true", help="Run evaluation only")
    parser.add_argument(
        "--no-log-file", action="store_true", help="Do not save log to file"
    )
    parser.add_argument(
        "--seed", type=int, default=-1, help="Force specific random seed"
    )
    parser.add_argument(
        "--out", type=str, default=None, help="Path to save evaluation results"
    )
    return parser.parse_args()


def seed_all(seed):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§"""
    if seed < 0:
        return
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def setup_env(args, cfg):
    """è®¾ç½®å·¥ä½œç›®å½•ã€æ—¥å¿—å’Œå¤‡ä»½é…ç½®"""
    # 1. ç¡®å®šå·¥ä½œç›®å½•
    # å¦‚æœ output-root æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äº PROJECT_ROOT
    out_root = Path(args.output_root)
    if not out_root.is_absolute():
        out_root = PROJECT_ROOT / out_root

    # æœ€ç»ˆå·¥ä½œç›®å½•: artifacts/exp_name
    work_dir = out_root / cfg.exp_name
    cfg.work_dir = str(work_dir)  # å°†è·¯å¾„å›å†™åˆ° config ä¸­æ–¹ä¾¿åç»­ä½¿ç”¨
    work_dir.mkdir(parents=True, exist_ok=True)

    # 2. ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())

    # 3. å¤‡ä»½é…ç½®æ–‡ä»¶ (ä»…åœ¨è®­ç»ƒæ¨¡å¼)
    if not args.eval_only:
        shutil.copy(args.config, work_dir / f"config_{timestamp}.yaml")

    # 4. åˆå§‹åŒ– Logger
    log_file = work_dir / f"{timestamp}.log" if not args.no_log_file else None
    logger = get_logger("MAP", log_file=log_file)

    logger.info(f"ğŸš€ Project Root: {PROJECT_ROOT}")
    logger.info(f"ğŸ“‚ Work Dir: {work_dir}")

    # 5. è®¾ç½®ç§å­
    real_seed = args.seed if args.seed >= 0 else cfg.seed
    seed_all(real_seed)
    logger.info(f"ğŸ² Random Seed: {real_seed}")

    return logger, timestamp


# ==============================================================================
# æ ¸å¿ƒé€»è¾‘: è®­ç»ƒä¸æµ‹è¯•
# ==============================================================================


@torch.no_grad()
def do_test(cfg, model, tokenizer, logger):
    """æ‰§è¡ŒéªŒè¯/æµ‹è¯•å¾ªç¯"""
    logger.info("Evaluation start...")

    val_loader = DataLoaderManager.get_dataloader(cfg, tokenizer, mode="val")
    model.eval()

    probs = []
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
    prog_bar = tqdm(val_loader, desc="Evaluating", leave=False)

    for batch in prog_bar:
        batch = to_gpu(batch)

        with torch.autocast(device_type="cuda", dtype=torch.bfloat16):
            # æ³¨æ„ï¼šè¿™é‡Œçš„å‚æ•°ä¼ é€’æ–¹å¼å‚è€ƒäº†åŸå§‹ train.pyï¼Œä½¿ç”¨äº†è§£æ„å‚æ•°è€Œé **batch
            # ç¡®ä¿ä½ çš„ Model forward å‡½æ•°æ¥å—è¿™äº›å‚æ•°
            logits = model(
                batch["input_ids"],
                batch["position_ids"],
                batch["suffix_ids"],
                batch["doc_ids"],
                batch["last_tokens"],
            )

        # å¤„ç†è¾“å‡ºï¼šflatten åæŒ‰ num_candidates åˆ‡åˆ†
        logits = logits.float().flatten()
        batch_probs = []
        batch_losses = []

        # é’ˆå¯¹æ¯ä¸ªæ ·æœ¬ï¼ˆä¸åŒæ•°é‡çš„ candidatesï¼‰åˆ‡åˆ† logits
        for _logits, _label in zip(
            logits.split(batch["num_candidates"]), batch["label"]
        ):
            # è®¡ç®— loss ä»…ç”¨äºè¿›åº¦æ¡æ˜¾ç¤º
            batch_losses.append(F.cross_entropy(_logits, _label))
            # ä¿å­˜æ¦‚ç‡ç”¨äºåç»­æŒ‡æ ‡è®¡ç®—
            batch_probs.append(_logits.float().softmax(dim=-1).data.cpu())

        loss = torch.stack(batch_losses).mean()
        prog_bar.set_description(f"Eval Loss: {loss.item():.4f}")
        probs.extend(batch_probs)

    # è½¬æ¢ç»“æœæ ¼å¼
    result = [prob.numpy() for prob in probs]

    # è°ƒç”¨ Dataset çš„è¯„ä¼°æ–¹æ³• (è®¡ç®— MAP@3 ç­‰)
    if hasattr(val_loader.dataset, "evaluate"):
        eval_result = val_loader.dataset.evaluate(result)
    else:
        eval_result = {"info": "Dataset does not support evaluation"}

    logger.info(f"Evaluation done. Metrics: {eval_result}")
    return result, eval_result


def do_train(cfg, model, tokenizer, logger):
    """æ‰§è¡Œè®­ç»ƒå¾ªç¯"""

    # 1. å‡†å¤‡æ•°æ®
    train_loader = DataLoaderManager.get_dataloader(cfg, tokenizer, mode="train")

    # 2. å‡†å¤‡ä¼˜åŒ–å™¨
    optimizer = OptimizerManager.get_optimizer(model, cfg)

    # 3. å‡†å¤‡ Scheduler
    # åŸä»£ç é€»è¾‘ï¼štotal_steps = epochs * len(loader)
    total_steps = cfg.max_epochs * len(train_loader)
    # å¦‚æœä½¿ç”¨äº†æ¢¯åº¦ç´¯ç§¯ï¼Œstep æ•°ä¼šå˜å°‘ï¼Œä½†åœ¨ reference ä»£ç ä¸­ä¼¼ä¹å¹¶æœªé™¤ä»¥ accumulation_steps
    # æˆ‘ä»¬è¿™é‡Œä¿æŒä¸ reference ä¸€è‡´ï¼ŒåŸºäº iter æ•°é‡
    lr_scheduler = OptimizerManager.get_scheduler(optimizer, cfg, total_steps)

    # ç¡®å®šç”¨äºè®°å½•æ—¥å¿—çš„å‚æ•°ç»„ ID (é€šå¸¸å–ç¬¬ä¸€ä¸ªæˆ–è€…å­¦ä¹ ç‡æœ€å¤§çš„é‚£ä¸ª)
    best_param_group_id = 0

    logger.info("Training start...")
    total_updates = 0
    max_epochs = cfg.max_epochs

    for curr_epoch in range(max_epochs):
        model.train()

        # åˆ›å»ºè¿›åº¦æ¡
        epoch_iterator = tqdm(train_loader, desc=f"Epoch {curr_epoch + 1}/{max_epochs}")

        for curr_iter, batch in enumerate(epoch_iterator):
            batch = to_gpu(batch)

            # --- Forward ---
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16):
                logits = model(
                    batch["input_ids"],
                    batch["position_ids"],
                    batch["suffix_ids"],
                    batch["doc_ids"],
                    batch["last_tokens"],
                )

            # --- Loss Calculation ---
            logits = logits.float().flatten()
            losses = []
            # å‚è€ƒåŸä»£ç ï¼šæ ¹æ® num_candidates åˆ‡åˆ† logits å’Œ labels
            for _logits, _label in zip(
                logits.split(batch["num_candidates"]), batch["label"]
            ):
                losses.append(F.cross_entropy(_logits, _label))

            loss = torch.stack(losses).mean()

            # --- Backward ---
            # ç‰¹æ®Šå¤„ç†ï¼šOffloadAdam éœ€è¦è¿™ä¸ªæ ‡å¿— (å‚è€ƒåŸä»£ç )
            if hasattr(optimizer, "ready_for_optimizer_step"):
                optimizer.ready_for_optimizer_step = True

            loss.backward()

            # --- Optimizer Step ---
            # å¦‚æœæœ‰æ¢¯åº¦ç´¯ç§¯ï¼Œéœ€è¦åœ¨æ­¤å¤„æ·»åŠ é€»è¾‘ã€‚å‚è€ƒä»£ç ä¸­ accumulation ä¼¼ä¹ä¸º 1 æˆ–æœªæ˜¾å¼å¤„ç†ç´¯ç§¯
            # è¿™é‡ŒæŒ‰ç…§åŸä»£ç é€»è¾‘ï¼šæ¯ä¸ª iter éƒ½ step
            if cfg.gradient_accumulation_steps > 1:
                # ç®€å•çš„ç´¯ç§¯é€»è¾‘è¡¥å……ï¼ˆå¦‚æœ config è®¾ç½®äº†ï¼‰
                if (curr_iter + 1) % cfg.gradient_accumulation_steps == 0:
                    optimizer.step()
                    optimizer.zero_grad(set_to_none=True)
                    lr_scheduler.step()
                    total_updates += 1
            else:
                optimizer.step()
                optimizer.zero_grad(set_to_none=True)
                lr_scheduler.step()
                total_updates += 1

            # --- Logging ---
            if total_updates % cfg.log_interval == 0:
                lr = optimizer.param_groups[best_param_group_id]["lr"]
                loss_val = loss.item()
                # æ˜¾å­˜ç›‘æ§
                max_mem_mb = torch.cuda.max_memory_allocated() / 1024.0 / 1024.0

                # æ›´æ–°è¿›åº¦æ¡æè¿°
                epoch_iterator.set_postfix(
                    loss=f"{loss_val:.4f}", lr=f"{lr:.2e}", mem=f"{max_mem_mb:.0f}M"
                )

                logger.info(
                    f"Epoch [{curr_epoch + 1}/{max_epochs}] Iter [{curr_iter + 1}/{len(train_loader)}] "
                    f"lr: {lr:.4e}, loss: {loss_val:.4f}, max_mem: {max_mem_mb:.0f}M"
                )

                # SwanLab Log
                swanlab.log(
                    {
                        "train/loss": loss_val,
                        "train/lr": lr,
                        "train/memory_mb": max_mem_mb,
                        "train/global_step": total_updates,
                        "train/epoch": curr_epoch + 1,
                    }
                )

        # === End of Epoch ===

        # 1. ä¿å­˜ Checkpoint
        ckpt_dir = Path(cfg.work_dir) / f"checkpoint_epoch_{curr_epoch + 1}"
        logger.info(f"Saving checkpoint to: {ckpt_dir}")
        model.save_pretrained(ckpt_dir)
        tokenizer.save_pretrained(ckpt_dir)

        # 2. éªŒè¯ (Evaluation)
        if (curr_epoch + 1) % cfg.eval_interval == 0:
            result, eval_result = do_test(cfg, model, tokenizer, logger)

            # SwanLab Log Metrics
            # å°† eval_result ä¸­çš„æ•°å€¼é¡¹è®°å½•åˆ° SwanLab
            swan_metrics = {
                f"val/{k}": v
                for k, v in eval_result.items()
                if isinstance(v, (int, float))
            }
            swan_metrics["val/epoch"] = curr_epoch + 1
            swanlab.log(swan_metrics)

            # ä¿å­˜é¢„æµ‹ç»“æœ
            res_path = Path(cfg.work_dir) / f"result_epoch_{curr_epoch + 1}.pth"
            torch.save(result, res_path)
            logger.info(f"Saved evaluation results to {res_path}")


# ==============================================================================
# Main
# ==============================================================================


def main():
    args = parse_args()

    # 1. è§£æé…ç½®æ–‡ä»¶è·¯å¾„
    config_path = Path(args.config)
    if not config_path.is_absolute():
        config_path = PROJECT_ROOT / config_path

    if not config_path.exists():
        print(f"âŒ Config file not found: {config_path}")
        sys.exit(1)

    print(f"âœ… Loading config from: {config_path}")
    cfg = ExperimentConfig.from_yaml(str(config_path))

    # 2. ç¯å¢ƒä¸æ—¥å¿—åˆå§‹åŒ–
    logger, timestamp = setup_env(args, cfg)

    # 3. SwanLab åˆå§‹åŒ– (ä»…åœ¨éè¯„ä¼°æ¨¡å¼ä¸‹)
    if not args.eval_only:
        swanlab_dir = Path(cfg.work_dir) / "swanlab"
        logger.info(f"Initializing SwanLab (logdir: {swanlab_dir})")

        swanlab.init(
            project="MAP-Math-Misconceptions",  # ä½ å¯ä»¥ä¿®æ”¹é¡¹ç›®å
            name=f"{cfg.exp_name}_{timestamp}",
            config=cfg.model_dump(),  # ä¼ å…¥æ‰€æœ‰é…ç½®
            logdir=str(swanlab_dir),
            mode="disabled"
            if args.no_log_file
            else "cloud",  # å¦‚æœä¸æƒ³ä¸Šä¼ äº‘ç«¯ï¼Œå¯æ”¹ä¸º "local"
        )

    # 4. åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨
    model, tokenizer = ModelManager.load_model(cfg)

    # å¤„ç† Resume from checkpoint (ä¼˜å…ˆä½¿ç”¨ config ä¸­çš„é…ç½®ï¼Œå…¶æ¬¡ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°)
    load_path = (
        args.load_from if args.load_from else cfg.llm_config.resume_from_checkpoint
    )

    if load_path:
        logger.info(f"ğŸ”„ Loading pretrained weights from: {load_path}")
        # è¿™é‡Œå‡è®¾ ModelManager.load_model å·²ç»åŠ è½½äº†åŸºç¡€ç»“æ„ï¼Œ
        # å¦‚æœ load_path æ˜¯å®Œæ•´çš„ HF ç›®å½•ï¼Œå¯ä»¥ç›´æ¥ç”¨ from_pretrained è¦†ç›–ï¼Œ
        # æˆ–è€…åŠ è½½ state_dictã€‚é‰´äº Qwen/GLM ä»£ç ï¼Œè¿™é‡Œç®€å•åœ°å‡è®¾ load_path æ˜¯æ¨¡å‹ç›®å½•
        # ä¸ºäº†ç¨³å¥ï¼Œæˆ‘ä»¬ä¿®æ”¹ cfg ä¸­çš„ backbone å†æ¬¡è°ƒç”¨ï¼ˆæˆ–è€…æ‰‹åŠ¨åŠ è½½æƒé‡ï¼‰
        # ç®€å•èµ·è§ï¼Œå¦‚æœæä¾›äº† load_pathï¼Œæˆ‘ä»¬é‡æ–°åŠ è½½ä¸€æ¬¡æ¨¡å‹
        cfg.llm_config.backbone = load_path
        # æ¸…ç†æ—§æ¨¡å‹æ˜¾å­˜ï¼ˆå¯é€‰ï¼‰
        del model
        torch.cuda.empty_cache()
        model, tokenizer = ModelManager.load_model(cfg)

    # å¤„ç† BF16 è½¬æ¢ (å‚è€ƒåŸä»£ç )
    if cfg.cast_to_bf16:
        logger.info("ğŸ”§ Casting model parameters to BF16 manually.")
        for p in model.parameters():
            p.data = p.data.to(torch.bfloat16)

    # 5. å¼€å§‹ä»»åŠ¡
    if args.eval_only:
        result, eval_result = do_test(cfg, model, tokenizer, logger)
        if args.out:
            torch.save(result, args.out)
            logger.info(f"Saved specific output to {args.out}")
    else:
        do_train(cfg, model, tokenizer, logger)

    logger.info("âœ¨ All finished.")


if __name__ == "__main__":
    main()
